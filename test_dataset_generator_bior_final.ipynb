{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:04, 24.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:09, 21.92it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import scipy.io as sio\n",
    "import cv2\n",
    "import pywt\n",
    "import pywt.data\n",
    "import matplotlib.image as image\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from os.path import join, isdir, abspath, dirname\n",
    "import matplotlib.pyplot as plt\n",
    "# Customized import.\n",
    "from networks import HED\n",
    "from datasets import BsdsDataset\n",
    "from utils import Logger, AverageMeter, \\\n",
    "    load_checkpoint, save_checkpoint, load_vgg16_caffe, load_pretrained_caffe\n",
    "\n",
    "\n",
    "# Set device.\n",
    "device = torch.device('cpu')\n",
    "\n",
    "\n",
    "def wav_trans_grayscale(images):\n",
    "    images = torchvision.utils.make_grid(images)\n",
    "    npimg = images.numpy()\n",
    "    img_np_right_dim = np.transpose(npimg, (1, 2, 0))\n",
    "    img_np_right_dim = cv2.cvtColor(img_np_right_dim, cv2.COLOR_BGR2GRAY)\n",
    "    coeffs2 = pywt.dwt2(img_np_right_dim, 'bior4.4')\n",
    "    LL, (LH, HL, HH) = coeffs2\n",
    "    return([LL, LH, HL, HH])\n",
    "\n",
    "\n",
    "\n",
    "def wav_trans(images):\n",
    "    # convert to numpy\n",
    "    images = images.numpy() # making images an nchw numpy array\n",
    "    images = images[0,0,:,:] # making images an hw numpy array\n",
    "    coeffs2 = pywt.dwt2(images, 'bior4.4')\n",
    "    LL, (LH, HL, HH) = coeffs2\n",
    "\n",
    "    # LL is an hw numpy array\n",
    "\n",
    "    # convert LL into a torch tensor of NCHW\n",
    "    \n",
    "    LL[LL>255.0] = 255.0\n",
    "    height = LL.shape[0]\n",
    "    width = LL.shape[1]\n",
    "    LL = torch.from_numpy(LL)\n",
    "    LL = torch.reshape(LL,(1, 1, height, width))\n",
    "    \n",
    "    return(LL)\n",
    "\n",
    "\n",
    "def WT_grayscale_path_input(path):  \n",
    "    \"\"\"Takes as input path string\"\"\"\n",
    "    orig_image = plt.imread(path)\n",
    "    if(len(orig_image.shape)==3):\n",
    "        gray_image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_image = orig_image\n",
    "    coeffs2 = pywt.dwt2(gray_image, 'bior4.4')\n",
    "    LL, (LH, HL, HH) = coeffs2\n",
    "    return [LL, LH, HL, HH]\n",
    "\n",
    "def im_save_path_modifier(input_path, mode):\n",
    "    \"\"\"\n",
    "    parameter: input_path is the path of the original image\n",
    "    parameter: mode is one of LL, LH, HL, HH\n",
    "    \"\"\"\n",
    "    dir_path = input_path[:16] + f'{mode}/' + input_path[16:input_path.rfind('/')]\n",
    "    image_path = input_path[:16] + f'{mode}/' + input_path[16:]\n",
    "    return(dir_path, image_path)\n",
    "\n",
    "def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "################################################\n",
    "# II. Datasets.\n",
    "################################################\n",
    "# Datasets and dataloaders.\n",
    "train_dataset = BsdsDataset(dataset_dir='./data/HED-BSDS', split='train')\n",
    "test_dataset  = BsdsDataset(dataset_dir='./data/HED-BSDS', split='test')\n",
    "train_loader  = DataLoader(train_dataset, batch_size=1,\n",
    "                           num_workers=4, drop_last=True, shuffle=True)\n",
    "test_loader   = DataLoader(test_dataset,  batch_size=1,\n",
    "                           num_workers=4, drop_last=False, shuffle=False)\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "\n",
    "\n",
    "for j, data in tqdm(enumerate(test_loader, 0)):\n",
    "    \n",
    "    images, path = data\n",
    "    \n",
    "    wav_trans_imlist = WT_grayscale_path_input(path[0])\n",
    "    wav_trans_imlist_names  = ['LL_bior', 'LH_bior', 'HL_bior', 'HH_bior']\n",
    "\n",
    "\n",
    "    for i in range(len(wav_trans_imlist)):\n",
    "\n",
    "        # saving image\n",
    "\n",
    "        dir_path, image_path = im_save_path_modifier(path[0], str(wav_trans_imlist_names[i]))\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        plt.imsave(image_path, wav_trans_imlist[i], cmap = 'gray')\n",
    "\n",
    "        \n",
    "    if(j%100==0):\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
